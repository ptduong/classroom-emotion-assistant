
<!DOCTYPE html>
<html>
<head>
  <title>Classroom Emotion Assistant</title>
  <meta charset="UTF-8">
  <style>
    body { font-family: Arial, sans-serif; text-align: center; padding: 20px; }
    video { width: 320px; height: 240px; border: 1px solid black; }
    canvas { display: none; }
    .results { display: flex; justify-content: center; gap: 40px; margin-top: 20px; }
    .result-box { border: 1px solid #ccc; padding: 10px; width: 300px; }
  </style>
</head>
<body>
  <h1>Classroom Emotion Assistant</h1>
  <video id="webcam" autoplay playsinline></video>
  <canvas id="canvas" width="320" height="240"></canvas>
  <div class="results">
    <div class="result-box">
      <h2>Image Emotion</h2>
      <div id="imageResult">Waiting...</div>
    </div>
    <div class="result-box">
      <h2>Audio Emotion</h2>
      <div id="audioResult">Waiting...</div>
    </div>
  </div>
  <button onclick="startApp()">Start</button>

  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@latest"></script>
  <script src="https://cdn.jsdelivr.net/npm/@teachablemachine/image@0.8.4/dist/teachablemachine-image.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/speech-commands@0.4.0/dist/speech-commands.min.js"></script>

  <script>
    const imageModelURL = "https://teachablemachine.withgoogle.com/models/vwVERB4xC/";
    const audioModelURL = "https://teachablemachine.withgoogle.com/models/TcB0ZWXJh/model.json";
    <!-- const imageModelURL = "YOUR_IMAGE_MODEL_URL"; -->
    <!-- const audioModelURL = "YOUR_AUDIO_MODEL_URL"; -->
    const audioMetadataURL = audioModelURL.replace("model.json", "metadata.json");

    let imageModel, audioModel;
    let webcam, canvas, ctx;

    async function startApp() {
      webcam = document.getElementById("webcam");
      canvas = document.getElementById("canvas");
      ctx = canvas.getContext("2d");

      // Start webcam
      const stream = await navigator.mediaDevices.getUserMedia({ video: true, audio: true });
      webcam.srcObject = stream;

      // Load image model
      imageModel = await tmImage.load(imageModelURL + "model.json", imageModelURL + "metadata.json");

      // Load audio model
      audioModel = await speechCommands.create("BROWSER_FFT", undefined, audioModelURL, audioMetadataURL);
      await audioModel.ensureModelLoaded();

      // Start audio listening
      audioModel.listen(result => {
        const scores = result.scores;
        const labels = audioModel.wordLabels();
        const topIndex = scores.indexOf(Math.max(...scores));
        document.getElementById("audioResult").innerText = labels[topIndex];
      }, { probabilityThreshold: 0.75 });

      // Start image prediction loop
      predictImageLoop();
    }

    async function predictImageLoop() {
      while (true) {
        ctx.drawImage(webcam, 0, 0, canvas.width, canvas.height);
        const prediction = await imageModel.predict(canvas);
        const topPrediction = prediction.reduce((prev, current) => (prev.probability > current.probability) ? prev : current);
        document.getElementById("imageResult").innerText = topPrediction.className;
        await new Promise(resolve => setTimeout(resolve, 500));
      }
    }
  </script>
</body>
</html>
